{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "os.chdir(\"/Users/rajpurkar/Documents/Code/ecg\")\n",
    "sys.path.append('./ecg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_FROM_MODEL = True\n",
    "LOAD_FROM_FILE = True\n",
    "\n",
    "model_paths = [\"saved/default/1498680570-155/0.426-0.848-011-0.339-0.873.hdf5\"]\n",
    "\n",
    "import load\n",
    "import json\n",
    "import util\n",
    "import predict\n",
    "\n",
    "if LOAD_FROM_MODEL is True:\n",
    "    params = util.get_model_params(model_paths[0])\n",
    "    x, gt, processor, dl = load.load_test(\n",
    "            json.load(open('./configs/test.json', 'r')),\n",
    "            train_params=params,\n",
    "            split='test')\n",
    "    model_probs = predict.get_ensemble_pred_probs(model_paths, x)\n",
    "elif LOAD_FROM_FILE is True:\n",
    "    model_probs = None\n",
    "    #file_to_load = open('./configs/train.json', 'r')\n",
    "    file_to_load = open('./configs/test.json', 'r')\n",
    "    params = json.load(file_to_load)\n",
    "    dl, processor = load.load_train(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = params[\"data_path\"]\n",
    "ext = '*_grp*.episodes.json'\n",
    "#ext = '*.episodes.json'\n",
    "\n",
    "def get_files(path):\n",
    "    for root, dirnames, filenames in os.walk(path):\n",
    "        for filename in fnmatch.filter(filenames, ext):\n",
    "            yield(os.path.join(root, filename))\n",
    "\n",
    "def patient_id(record):\n",
    "    return os.path.basename(record).split(\"_\")[0]\n",
    "\n",
    "class_patients = defaultdict(set)\n",
    "for f in tqdm(get_files(path)):\n",
    "    jfile = json.load(open(f, 'r'))\n",
    "    for episode in jfile['episodes']:\n",
    "        rhythm_name = episode['rhythm_name']\n",
    "        if rhythm_name == 'SUDDEN_BRADY':\n",
    "            rhythm_name = u'CHB'\n",
    "        if rhythm_name == 'NSR':\n",
    "            rhythm_name = u'SINUS'\n",
    "        class_patients[rhythm_name].add(patient_id(f))\n",
    "\n",
    "for (k, v) in class_patients.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for (k, v) in sorted(class_patients.items()):\n",
    "    lv = len(v)\n",
    "    total += lv\n",
    "    print(k, lv)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = dl.x_test\n",
    "y = dl.y_test\n",
    "\n",
    "def from_one_hot_to_int(label):\n",
    "    return np.argmax(label, axis=-1)\n",
    "\n",
    "def get_x_y_predictions_at_index(index, probs=None):\n",
    "    x_sample = x[index]\n",
    "    y_sample = from_one_hot_to_int(y[index])\n",
    "    y_prediction = None\n",
    "    if probs is not None:\n",
    "        y_prediction = np.argmax(probs[index], axis=-1)\n",
    "    return x_sample, y_sample, y_prediction\n",
    "\n",
    "def get_sample_from_classes(\n",
    "        categories, min_mistakes = 20, num_tries = 1000, only_classes=False, probs=None):\n",
    "    classes = np.array([processor.class_to_int[c] for c in categories])\n",
    "    y_maxed = np.argmax(y, axis=-1)\n",
    "    indices = np.where(np.array([np.in1d(classes, row).all() for row in y_maxed]))[0]\n",
    "    for _ in range(num_tries):\n",
    "        index = random.choice(indices)\n",
    "        y_prediction = None\n",
    "        x_sample, y_sample, y_prediction = get_x_y_predictions_at_index(index, probs=probs)\n",
    "        if only_classes:\n",
    "            if (set(np.unique(y_sample)) != set(np.unique(classes))):\n",
    "                continue\n",
    "        num_wrong = 0\n",
    "        if y_prediction is None:\n",
    "            break\n",
    "        num_wrong = np.sum(y_sample != y_prediction)\n",
    "        if (num_wrong > min_mistakes):\n",
    "            print(\"Prediction got wrong \" +  str(num_wrong * 1.0 / len(y_sample)))\n",
    "            break\n",
    "    return x_sample, y_sample, y_prediction, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truths = np.argmax(y, axis=2)\n",
    "num_outputs_for_thirty_seconds = len(truths[0])\n",
    "truths_flat = truths.flatten()\n",
    "classes_unique, counts = np.unique(truths_flat, return_counts=True)\n",
    "classes_u = np.array(processor.classes)[classes_unique]\n",
    "num_hours = (counts * 30 / num_outputs_for_thirty_seconds) / 3600.0\n",
    "for pair in zip(classes_u, num_hours):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "from itertools import groupby\n",
    "#plt.rcParams[\"font.family\"] = \"SFCompactText\"\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 6)\n",
    "\n",
    "def from_int_to_name(l):\n",
    "    return processor.classes[l]\n",
    "\n",
    "def draw_sample(x_sample, y_sample, y_prediction, step, show_label=True, save=False, small_frame=False):\n",
    "    colors = cm.Pastel2(np.linspace(0, 1, 20))\n",
    "    y_times = np.linspace(step/2, len(x_sample) - step/2, len(y_sample))\n",
    "    if show_label is True:\n",
    "        grouped_labels = [(k, sum(1 for i in g)) for k,g in groupby(y_sample)]\n",
    "        acc = 0\n",
    "        seen = {}\n",
    "        for label, number in grouped_labels:\n",
    "            params = {\n",
    "                \"color\": colors[label],\n",
    "                \"alpha\": 0.5,\n",
    "                \"lw\": 0\n",
    "            }\n",
    "            if label not in seen:\n",
    "                label_name = from_int_to_name(label)\n",
    "                params[\"label\"] = label_name\n",
    "                seen[label] = True\n",
    "            plt.axvspan(\n",
    "                acc * step,\n",
    "                (acc + number) * step, **params)\n",
    "            acc += number\n",
    "    print(np.array(processor.classes)[y_sample])\n",
    "    if y_prediction is not None:\n",
    "        print(np.array(processor.classes)[y_prediction])\n",
    "    plt.plot(x_sample, color='#000000', alpha=1)\n",
    "    plt.legend(loc=\"best\", prop={'size':14})\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.tight_layout()\n",
    "    if small_frame is True:\n",
    "        plt.xlim([0, 1500])\n",
    "    if save is True:\n",
    "        plt.savefig(str(np.unique(np.array(processor.classes)[y_sample])[0]) + \"-\" + str(index) + '.pdf', dpi=400, format='pdf',bbox_inches='tight',pad_inches=0)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#for class_indiv in processor.classes:\n",
    "x_sample, y_sample, y_prediction, index = get_sample_from_classes([u'VT'], only_classes=False, probs=model_probs, min_mistakes=0)\n",
    "\n",
    "\n",
    "#index = 2605\n",
    "#x_sample, y_sample, y_prediction = get_x_y_predictions_at_index(index)\n",
    "\n",
    "step = params[\"step\"] if \"step\" in params else 256\n",
    "draw_sample(x_sample, y_sample, y_prediction, step, save=False, show_label=True, small_frame=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import human_performance\n",
    "from tabulate import tabulate\n",
    "\n",
    "f1_data = []\n",
    "for metric in ['seq', 'set']:\n",
    "    # models\n",
    "    evaluator = evaluate.evaluate_multiclass(\n",
    "        gt, model_probs, processor.classes, metric, ', '.join(model_paths), display_scores=False)\n",
    "    model_plotMat, model_support, class_names = evaluate.parse_classification_report(evaluator.scorer.report)\n",
    "    model_f1 = model_plotMat[:, 2]\n",
    "    f1_data.append(model_f1)\n",
    "\n",
    "    # humans\n",
    "    human_ground_truths, human_probs = human_performance.human_gt_and_probs(params, x, gt, processor)\n",
    "    evaluator = evaluate.evaluate_multiclass(\n",
    "        human_ground_truths, human_probs, processor.classes, metric, ', '.join(model_paths), display_scores=False)\n",
    "    human_plotMat, human_support, class_names = evaluate.parse_classification_report(evaluator.scorer.report)\n",
    "    human_f1 = human_plotMat[:, 2]\n",
    "    f1_data.append(human_f1)\n",
    "\n",
    "f1_data = np.array(f1_data).T\n",
    "cell_text = []\n",
    "for row, class_name in zip(f1_data, class_names):\n",
    "    cell_text.append([class_name] + ['%1.3f' % x for x in row])\n",
    "\n",
    "table = tabulate(\n",
    "    cell_text, tablefmt=\"latex\", floatfmt=\".3f\",\n",
    "    headers=[\"Model seq\", \"Human seq\", \"Model set\", \"Human set\"])\n",
    "\n",
    "rows = []\n",
    "import re\n",
    "for row in table.split('\\n'):\n",
    "    elems = re.split('\\s+', row)\n",
    "    if len(elems) > 2 and \"seq\" not in elems:\n",
    "        for start in [3, 7]:\n",
    "            end = start+2\n",
    "            winner = start if float(elems[start]) > float(elems[end]) else end\n",
    "            elems[winner] = \"\\\\textbf{\" + elems[winner] + \"}\"\n",
    "    row = \" \".join(elems)\n",
    "    rows.append(row)\n",
    "table = \"\\n\".join(rows)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_text = []\n",
    "for row in f1_data:\n",
    "    cell_text.append(['%1.3f' % x for x in row])\n",
    "\n",
    "colLabels=(\"Model\", \"Human\", \"Model\", \"Human\")\n",
    "nrows, ncols = len(cell_text)+1, len(colLabels)\n",
    "hcell, wcell = 0.3, 1.\n",
    "hpad, wpad = 0, 1    \n",
    "\n",
    "fig=plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.axis('off')\n",
    "#do the table\n",
    "# Add headers and a table at the bottom of the axes\n",
    "header_0 = plt.table(cellText=[['']*2],\n",
    "                     colLabels=['Seq F1', 'Set F1'],\n",
    "                     loc='bottom',\n",
    "                     bbox=[0, 0.9, 0.5, 0.2]\n",
    "                     )\n",
    "\n",
    "table = plt.table(\n",
    "    cellText=cell_text,\n",
    "    rowLabels=class_names,\n",
    "    colLabels=colLabels,\n",
    "    loc='bottom',\n",
    "    bbox=[0, 0, .5, 1.0])\n",
    "plt.subplots_adjust(left=0.2, bottom=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import featurize\n",
    "\n",
    "bp = featurize.BandPassFilter()\n",
    "x_new = bp.filt(x_sample)\n",
    "plt.plot(x_sample, label=\"original\")\n",
    "plt.plot(x_new, label=\"bandpassed\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Improvement With Increase in Training Data\n",
    "Requires a csv denoting magnification factor per class, and another denoting f1 accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "from numpy import genfromtxt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def measure(file1, file2):\n",
    "    train = np.fliplr(genfromtxt(file1, delimiter=',').T)\n",
    "    accuracy = np.fliplr(genfromtxt(file2, delimiter=',').T)\n",
    "    labels = ['NSR', 'NOISE', 'AFIB', 'TRIGEMINY', 'SVT', 'WENCKEBACH', \\\n",
    "              'AFL', 'BIGEMINY', 'JUNCTIONAL', 'AVB_TYPE2', 'VT', 'SUDDEN_BRADY', 'EAR', 'PAUSE', 'IVR']\n",
    "    for index in range(train.shape[0]):\n",
    "        x = train[index]\n",
    "        y = accuracy[index]\n",
    "        spl = UnivariateSpline(x, y, k=1)\n",
    "        x_r = np.arange(0, max(x) + 1)\n",
    "        plt.plot(x_r, spl(x_r), label=labels[index])\n",
    "        plt.scatter(x, y)\n",
    "        plt.ylabel('Class F1')\n",
    "        plt.xlabel('# Examples')\n",
    "\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# measure('../train.csv', '../acc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-ocurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask = np.zeros((dl.y_train.shape[0], len(processor.classes)))\n",
    "for i, row in enumerate(np.argmax(dl.y_train, axis=-1)):\n",
    "    indices = np.unique(row)\n",
    "    mask[i, indices] = 1\n",
    "\n",
    "coocurrence = np.dot(mask.T, mask)\n",
    "\n",
    "def plot_coocurrence(cooccurence):\n",
    "    cmap = plt.cm.Reds\n",
    "    plt.imshow(np.log10(coocurrence + 1), interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Co-occurence matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(processor.classes))\n",
    "    plt.xticks(tick_marks, processor.classes, rotation=90)\n",
    "    plt.yticks(tick_marks, processor.classes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_coocurrence(coocurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Agreement Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix_matrix\n",
    "args = util.get_object_from_dict(data_path=\"../data/label_review\")\n",
    "params = json.load(open('../configs/default.json', 'r'))\n",
    "params[\"val_frac\"] = 0\n",
    "params[\"extension\"] = '_rev0.episodes.json'\n",
    "dl1 = load.load(args, params)\n",
    "y1 = dl1.y_train\n",
    "params[\"extension\"] = '_rev1.episodes.json'\n",
    "dl2 = load.load(args, params)\n",
    "y2 = dl2.y_train\n",
    "\n",
    "y1_flat = np.argmax(y1, axis=-1).flatten().tolist()\n",
    "y2_flat = np.argmax(y2, axis=-1).flatten().tolist()\n",
    "\n",
    "print(classification_report(\n",
    "        y1_flat, y2_flat,\n",
    "        target_names=dl.classes))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y1_flat, y2_flat).tolist()\n",
    "import evaluate\n",
    "evaluate.plot_confusion_matrix(np.log10(np.array(cnf_matrix) + 1), dl.classes)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
