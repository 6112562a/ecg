{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (9, 6)\n",
    "import random\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../ecg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOAD_FROM_FILE = False\n",
    "LOAD_FROM_MODEL = False\n",
    "model_path = \"../saved/3.1/1485643942/0.317-0.908-033-0.222-0.927.hdf5\"\n",
    "\n",
    "import load\n",
    "import json\n",
    "import util\n",
    "\n",
    "args = util.get_object_from_dict(data_path=\"../data\")\n",
    "\n",
    "if LOAD_FROM_FILE is True:\n",
    "    params = json.load(open('../configs/vanilla_load.json', 'r'))\n",
    "elif LOAD_FROM_MODEL is True:\n",
    "    params = util.get_model_params(model_path)\n",
    "else:\n",
    "    params = {\"step\": 256, \"toy\": False}\n",
    "\n",
    "step = params[\"step\"]\n",
    "\n",
    "dl = load.load(args, params)\n",
    "print(dl.class_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = None\n",
    "if LOAD_FROM_MODEL is True:\n",
    "    predictions = np.load(open(util.get_prediction_path_for_model(model_path, 'test'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = dl.x_test\n",
    "y = dl.y_test\n",
    "\n",
    "def from_one_hot_to_int(label):\n",
    "    return np.argmax(label, axis=-1)\n",
    "\n",
    "def get_x_y_predictions_at_index(index):\n",
    "    x_sample = x[index]\n",
    "    y_sample = from_one_hot_to_int(y[index])\n",
    "    y_prediction = None\n",
    "    if predictions is not None:\n",
    "        y_prediction = np.argmax(predictions[index], axis=-1)\n",
    "    return x_sample, y_sample, y_prediction\n",
    "\n",
    "def get_sample_from_classes(categories, min_mistakes = 20, num_tries = 1000):\n",
    "    classes = np.array([dl.class_to_int[c] for c in categories])\n",
    "    y_maxed = np.argmax(y, axis=-1)\n",
    "    indices = np.where(np.array([np.in1d(classes, row).all() for row in y_maxed]))[0]\n",
    "    for _ in range(num_tries):\n",
    "        index = random.choice(indices)\n",
    "        y_prediction = None\n",
    "        x_sample, y_sample, y_prediction = get_x_y_predictions_at_index(index)\n",
    "        num_wrong = 0\n",
    "        if y_prediction is None:\n",
    "            break\n",
    "        num_wrong = np.sum(y_sample != y_prediction)\n",
    "        if (num_wrong > min_mistakes):\n",
    "            print(\"Prediction got wrong \" +  str(num_wrong * 1.0 / len(y_sample)))\n",
    "            break\n",
    "    return x_sample, y_sample, y_prediction\n",
    "\n",
    "x_sample, y_sample, y_prediction = get_sample_from_classes([u'NSR', u'NOISE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "\n",
    "def from_int_to_name(l):\n",
    "    return dl.classes[l]\n",
    "\n",
    "def draw_sample(x_sample, y_sample, y_prediction):\n",
    "    colors = cm.rainbow(np.linspace(0, 1, 20))\n",
    "    y_times = np.linspace(step/2, len(x_sample) - step/2, len(y_sample))\n",
    "    for y_chosen in [y_sample]:\n",
    "        for y_uniq in np.unique(y_chosen):\n",
    "            plt.vlines(\n",
    "                y_times[y_chosen == y_uniq],\n",
    "                min(x_sample),\n",
    "                max(x_sample),\n",
    "                label=from_int_to_name(y_uniq),\n",
    "                color=colors[y_uniq],\n",
    "                alpha=1\n",
    "            )\n",
    "        y_times += 20\n",
    "    print(np.array(dl.classes)[y_sample])\n",
    "    print(np.array(dl.classes)[y_prediction])\n",
    "    plt.plot(x_sample, color='#999999', alpha=1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "draw_sample(x_sample, y_sample, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import featurize\n",
    "\n",
    "bp = featurize.BandPassFilter()\n",
    "x_new = bp.filt(x_sample)\n",
    "plt.plot(x_sample, label=\"original\")\n",
    "plt.plot(x_new, label=\"bandpassed\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Improvement With Increase in Training Data\n",
    "Requires a csv denoting magnification factor per class, and another denoting f1 accuracy per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "from numpy import genfromtxt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "def measure(file1, file2):\n",
    "    train = np.fliplr(genfromtxt(file1, delimiter=',').T)\n",
    "    accuracy = np.fliplr(genfromtxt(file2, delimiter=',').T)\n",
    "    labels = ['NSR', 'NOISE', 'AFIB', 'TRIGEMINY', 'SVT', 'WENCKEBACH', \\\n",
    "              'AFL', 'BIGEMINY', 'JUNCTIONAL', 'AVB_TYPE2', 'VT', 'SUDDEN_BRADY', 'EAR', 'PAUSE', 'IVR']\n",
    "    for index in range(train.shape[0]):\n",
    "        x = train[index]\n",
    "        y = accuracy[index]\n",
    "        spl = UnivariateSpline(x, y, k=1)\n",
    "        x_r = np.arange(0, max(x) + 1)\n",
    "        plt.plot(x_r, spl(x_r), label=labels[index])\n",
    "        plt.scatter(x, y)\n",
    "        plt.ylabel('Class F1')\n",
    "        plt.xlabel('# Examples')\n",
    "\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# measure('../train.csv', '../acc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-ocurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = np.zeros((dl.y_train.shape[0], dl.output_dim))\n",
    "for i, row in enumerate(np.argmax(dl.y_train, axis=-1)):\n",
    "    indices = np.unique(row)\n",
    "    mask[i, indices] = 1\n",
    "\n",
    "coocurrence = np.dot(mask.T, mask)\n",
    "\n",
    "def plot_coocurrence(cooccurence):\n",
    "    cmap = plt.cm.Reds\n",
    "    plt.imshow(np.log10(coocurrence + 1), interpolation='nearest', cmap=cmap)\n",
    "    plt.title('Co-occurence matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(dl.classes))\n",
    "    plt.xticks(tick_marks, dl.classes, rotation=90)\n",
    "    plt.yticks(tick_marks, dl.classes)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_coocurrence(coocurrence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Agreement Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "args = util.get_object_from_dict(data_path=\"../data/label_review\")\n",
    "params = json.load(open('../configs/default.json', 'r'))\n",
    "params[\"val_frac\"] = 0.5\n",
    "params[\"extension\"] = '_rev0.episodes.json'\n",
    "dl1 = load.load(args, params)\n",
    "y1 = np.concatenate((dl1.y_train, dl1.y_test), axis=0)\n",
    "params[\"extension\"] = '_rev1.episodes.json'\n",
    "dl2 = load.load(args, params)\n",
    "y2 = np.concatenate((dl2.y_train, dl2.y_test), axis=0)\n",
    "\n",
    "y1_flat = np.argmax(y1, axis=-1).flatten().tolist()\n",
    "y2_flat = np.argmax(y2, axis=-1).flatten().tolist()\n",
    "\n",
    "print(classification_report(\n",
    "        y1_flat, y2_flat,\n",
    "        target_names=dl.classes))\n",
    "\n",
    "cnf_matrix = confusion_matrix(y1_flat, y2_flat).tolist()\n",
    "import evaluate\n",
    "evaluate.plot_confusion_matrix(np.log10(np.array(cnf_matrix) + 1), dl.classes)\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
